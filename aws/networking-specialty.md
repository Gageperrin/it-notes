# AWS Certified Advanced Networking Specialty

These are my notes for the AWS ANS-C00 exam. I have taken the content from [Adrian Cantrill's course](https://learn.cantrill.io/p/aws-certified-advanced-networking-specialty) for this exam, Tutorial Dojo's practice tests, and the official AWS documentation. 

These notes assume full and prior knowledge of requisite material for the Solutions Architect Associate and Professional exams and will only pre-requisite content in brief, if at all.

## Networking and Tech Fundamentals

### Networking Starter Pack

# Networking Starter Pack

The OSI Seven Layer Model of Networking:
1. Physical
2. Data Link
3. Network
4. Transport
5. Session
6. Presentation
7. Application

Media layers are 1-3, while host layers are 4-7.

#### 1 - Physical ####

Physical medium can be a copper wire (electrical), fibre (light), or WIFI (RF).

Layer 1 specfications define the transmission and reception of **raw bit streams** between a device and a shared physical medium. It define things like voltage levels, timing, rates, distances, modulation, and connectors.

A networking device called a hub can connect multiple devices. Anything received on any port is transmitted on every other port, including errors and collisions.

No device addressing, all data is processed by all devices. If multiple devices transmit at once, then a collision occurs. There are no media access control and no collision detection at this layer. Layer 1, in effect, scales very poorly.

Fibre use a thin glass or plastic core surrounded by protection to transmit data through light over the cable. It can cover larger distances at higher speeds than traditional copper wiring and it is more resistant to EMI or water ingress. 

The cable (jacket) influences distance, speed, and features while connectors influence what hardware the cable can be used with. Fibre is expressed as diameter of the core/diameter of the cladding (in microns), such as 9/125. The cladding is a boundary surrounding the core to contain the light. The buffer is a combination of internal coating and strenghtening fibres designed to absorb shock and provide strength to the core. The cable jacket surrounds the buffer.

Single-mode fibre allows one ray of light only, no bouncing or distortion. Best for longest distances with the highest bandwidth. Multi-mode by contrast allows for multiple rays of light at once which is better for speed at short distances but can cause distortion with distance. Single-mode usually has a yellow jacket, while multi-mode has orange or aqua colored jacket.

Fibre optic transceiver modules (SFP or MINI GBIC) generate or receives light from the fiber cable. The transceivers are also single-mode or multi-mode, optimized for the type of cable used. Common transceivers include 1000BASE-LX, 10GBASE-LR, and 100GBASE-LR4 (the types used in AWS Direct Connect).
#### 2 - Data Link ####

Devices at this layer have a unique hardware address (MAC address). It is 46 bits in hexidecimal, 24 bits for manufacturer. Frames are generated by the source device, and they can be addressed to a destination or broadcast.

Data link frame: Preamble of 56 bits & SFD 8 bits - Destination MAC address - Source MAC address - ET 16 bits - Payload (46-1500 bytes) -> FCS 32 bits.

Preamble -> MAC Header -> Payload

The payload is the data the frame carries from source to destination. It is generally provided by layer 3, and the EtherType (ET) attribute defines which Layer 3 protocol is used.

Layer 2 solves Layer 1 collision problems by controlling access to the physical medium through CSMA/CD. Process:
(1) Source device creates a Frame intending to send data to destination device.
(2) Source device checks carrier.
(3) If no carrier, then layer 1 takes the frame data, converts it to physical standard and transmits.
(4) Layer 1 on the destination device receives and passes frame to Layer 2 destination device.
(5) If destination device needs to send data, it builds a frame
(6) It detects a carrier, so it waits before transmitting.
(7) Once the first frame is finishing transmitting, it transmits the second frame.
(8) If collisions are detected (CD) both back off for a time and re-tried at a random time. Keeps re-trying with increased backup time if further collisions occur.

Layer 2 using a HUB is a weak solution because of collision and errors. It is better to use a Switch.

Switches understand frames and MAC addresses. They maintain a MAC address table which starts off as empty. As the switch received frames on its ports, it learns the connected devices and populates the MAC address table.

Switches store and forward frames. This means only valid frames are forwarded. Collisions are isolated on the port they occur. Every X port has X collision domains. It allows switches to scale.

#### 3 - Network ####

Two Local Area Networks need to be connected over a large distance. Layer 2 will not suffice for this communication. Ethernet is a Layer 2 protocol. Long distance point to point links will use more suitable protocols such as PPP/MPLS/ATM.

Internet Protocol (IP) is a Layer 3 protocol which adds cross-network IP addressing and routing to move data between Local Area Networks without direct P2P links. IP packets are moved step by step from source to destination via intermediate networks. Encapsulated in different frames along the way. Router devices (L3) remove frame encapsulation and add new frame encapsulation at every hop.

Source IP address and destination IP address included as well as Layer 4 protocol values. Similar to IPv6 packets with bigger source and destination IP addresses.

### IPv4 Addressing

133.33.3.7 is dotted decimal notation 4 values between 0 and 255. All IP Address have a network part (coming from the left). The host part is the remainder allotted from the right. If the network part of two IP addresses match, it means they are on the same IP network. If not, they are on different networks.

IP addresses are only represented in dotted decimal for humans. They are actually binary. Four sets of octets (8 bits). Total of 32 bits. 133.33.3.7 has a /16 prefix. 16 bits of the IP are the network, and the remaining bits are for the hosts. IP addresses are assigned by machine (DHCP) or humans.

### Subnets

Subnet masks are configured on Layer 3 interfaces. They allow a hsot to determine if an IP address is local or remote and whether it needs to use a gateway. A subnet mask is configured on a host device in addition to an IP address.

A subnet mask is a dotted decimal version of a binary number which indicates which part of an IP address is network (1) and which part is host (0). So a subnet mask of 255.255.0.0 designates the first two octets for the network (the 1's), and the last two octets for the host (the 0's).

133.33.3.7 IP address with a subnet of 255.255.0.0 has a network start of 133.33.0.0 and ends at 133.33.255.255.

### Route Tables and Routes

A source sends its IP packet on the default route 0.0.0.0/0 to the router. The router has multiple route tables to use for selection. The router compares the packet destination IP and route table for matching destinations. The more specific prefixes are preferred (0 is lowest, 32 is highest). 

Packet is forwarded on to the next hop or the target. (The higher the number after the slash, the more specific the prefix.) Packets are routed through sequential hops from source to the destination across the Internet.

### Address Resolution Protocol (ARP)

But how to find the MAC address for a given IP address? The Address Resolution Protocol.

Within a local network, data is moved via Layer 2 frames over Layer 1. ARP discovers which MAC relates to a given IP as the data is handed to the Layer 3 destination. ARP broadcasts on Layer 2 asking for a IP address. The destination IP address responds with the MAC address. The source device passes the frame using the destination MAC address obtained via ARP to Layer 1 for transmission.

Layer 1 on the destination device hands off the raw data to the frame on Layer 2. The destination MAC matches the address provided, so Layer 2 strips the frame and passes the payload to Layer 3. The packet matches the destination IP address, so the data is handed on to the destination.

### IP Routing

Outside of a local network. Subnet mask and desitnation IP show the destination IP is not local. It wraps it up in a frame. ARP is used to find the MAC address of the default gateway. The packet is given the router's IP and encapsulated in a frame. The destination is the router.

The router removes the frame around the packet and reviews packet IP destination. The router has a route for the network that the destination IP is in. It creates a new frame with a second router as the destination MAC. The packet is unchanged as it remains in the frame payload. The frame is sent to the sefcond router.

The second router removes the frame around the packet. The router confirms the destination IP is on the same network and uses ARP to get the MAC address of the destination. It creates a new frame with the destination MAC address and encapsulates the packet. The frame is sent to the destination device, the final destination.

### Summary

* IP Addresses add cross network addressing
* ARP
* Route
* Route Tables
* Router (encapsulates through Layer 2)
* Device to device over the Internet

#### 4 - Transport ####

Layer 3 has no method for channeling communications, and data can be sent out of order. Each packet is routed independently. Routing decisions are per packet. Per packet routing can have delays, and some packets can even be lost in transit.

Layer 4 consists of TCP (Transmission Control Protocol) and UDP traffic. TCP is slower and more reliable. UDP is faster but less reliable. 

### TCP

TCP segments are placed inside IP packets. Segments do not have source or destination IP addresses because the packets provide device addressing. 

The TCP header includes:
* A source and destination port. Ports allow for multiple streams of communication. 
* A sequence number for ordering and identfying segments in a connection.
* The acknowledgent field is the way that one side can indicate that it has received a segment in a sequence.
* Flags N' Things is another aspect used to close connection, synchronize sequence numbers, and reserve some space.
* The Window allows the receivers to control the rate at which the receiver receives the data. * * * Checksum is used for error checking and arrange for retransmission of the data.
* The urgent point marks latency-sensitive traffic. 

Alongside the header is the payload of data, all wrapped in the TCP segment.

TCP is connection based. A conneciton is established using a random port on a client and a known port on the server. The connection is bilateral.

Layer 4 divides data into segments linked to a connection with error checking, ordering, and retransmission not possible at Layer 3. 

A well known port like tcp/443 is used as a destination while an ephemeral port like tcp/23060 is used as a source. The connection is split between each direction. This is why there are two rules in NACL, one for outbound and one for response traffic.

TCP Well known ports:
* tcp/80 - HTTP & tcp/443 HTTPS
* tcp/22 - SSH
* tcp/25 - SMTP (email)
* tcp/21 - TELNET
* tcp/3389 Remote Desktop Protocol
* tcp/3306 MySQL/MariaDB/Aurora

TCP requires a three way handshake initiated through Flags. Flags can be set to alter the connection. `FIN` can be used to close, `ACK` for acknowledgements, and `SYN` to synchronize sequence numbers.

Send a segment with `SYN` sequence set from the client to the server ('cs'. `SYN-ACK` on server side will increment the sequence set. It picks a random sequence and sends the segment. It sends on a sequence of 'cs+1' and a sequence 'ss' back to the client. The client `ACK` increments both the sequence and the acknowledgement. Sends the acknowledgement back as a sequence 'cs+2' and the sequence back as an acknowledgement 'ss+1'. The connection is subsequently established and the client can send data.


#### 5 - Session ####

A stateless firewall does not understand the state of traffic. It needs two rules for both outbound and response traffic.

A stateful firewall sees one thing. Allowing the outbound implicity allows the inbound (e.g. AWS security group).

#### Extra - NAT ####

NAT is designed to overcome IPv4 shortages by adjusting packets of source and destination addresses to allow transit across different networks. NAT translates private IPv4 addresses to public ones.

A Static NAT device translates 1 private address to 1 fixed public address (IGW). A Dynamic NAT translates 1 private address to first available public address. Port Address Translation (PAT) translates many private addresses to 1 public address (NATGW).

Static NAT: The router maintains a NAT table, it maps PrivateIP : PublicIP (1:1). Packets are generated as normal with a private source IP and an external destination IP. If a Public IP has been allocated to the Private IP, the source address of the packet is translated as it passes through the NAT device.

Dynamic NAT: The router maintains a NAT table, it maps Private IP: Public IP in the same way as Static NAT, but the allocations are temporary. Multiple devices can use the same allocation over time if there is no overlap. In the public Internet, only one private IP will be mapped to the the public IP at any time, it is still 1:1 for the duration of the allocation. If the Public IP pool is exhausted then external access can fail.

PAT: The NAT Device records the source IP and source port. It replaces the source IP with the single public IP and a public source port allocated from a pool which allows IP overloading (many to one). Return traffic has the public IP of the NAT device and the destination port. Public port and Public IP are translated to Private port and Private IP. This is how AWS NAT Gateways work.

#### Subnetting ####

The IPv4 standard was standardized in 1981 through the RFC791 document. They occupy ranges between 0.0.0.0 and 255.255.255.255. This contains 4,294,967,296 IP addresses. It was originally managed by IANA but has since been delegated to regional authorities. All public IPv4 addresses are allocated, but there are private addresses that can be used freely.

It was historically divided into multiples classes such as class A (0.0.0.0 -> 127.255.255.255) with 128 networks for large networks and businesses. This has been largely handed over to regional authorities. Class B starts at 128.0.0.0 and ends at 191.255.255.255 and contains 16,384 for smaller businesses but this was also handed over to regional authorities. Class C (192.0.0.0 -> 223.255.255.255) with 2,097,152 networks for even smaller businesses. Class D (multi-cast) and Class E (reserved) were also set up.

IPv4 is now defined by the standard RFC1918. The first private range (10.0.0.0 - 10.255.255.255) contains 16,777,216 IP addresses. The next private range runs from 172.16.0.0 to 172.31.255.255 with 16 networks that contain 65,536 IPv4 addresses each. 192.168.0.0 - 192.168.255.255 is the third group with 256 networks with 256 IPv4 addresses each (used for home routing). It is best practice to never configure overlapping CIDR ranges.

A subnet is a prefix value `/` after the IPv4 address. For example, 10.16.0.0 starts at 10.16.0.0 and ends at 10.16.255.255. This can be sub-netted to create four smaller networks by splitting the network into two by making it `/17` with ranges 10.16.0.0/17 and 10.16.128.0/17. This second netowrk can then be split again `/18` into 10.16.128.0/18 and 10.16.192.0/18.


#### DDoS Attacks ####

DDoS are attacks designed to overload websites and compete against legitimate connections. They are often distributed so blocking individual IP ranges does not work. There are several types of attacks. Application Layer HTTP Floods push overwhelming traffic at Layer 7. Protocol attacks are SYN floods spoof a source IP address and initiate a connection attempt. The server tries to perform the handshake but is unable to locate the spoofed IP and so waits a specified duration to try to find it. Volumetric attacks rely on DNS amplification push a large amount of data to DNS server to overwhelm them with requests. Botnets are the machines that execute these attacks, usually installed as malware.

These attacks cannot be defended against using standard network protections.

#### SSL and TLS ####

Secure Sockets Layer (SSL) and Transport Layer Security (TLS) essentially do the same thing but TLS is newer. They provide privacy and data integrity between the client and server. They ensure that communications are encrypted. TLS starts with asymmetric encryption and then moves to symmetric encryption to save computation resources. TLS also provides server and client identity verification and ensures a reliable connection to prevent tampering.

There are three phases: cipher suites, authentication, and then key exchange. Cipher Suite is a group of algorithms for the communication process. The client and server need the same Cipher Suite available in order to communicate securely. This first phase is how they agree to communicate. 

In the second phase, the client validates the server certificate. The server should have a publicly trusted Certificate Authority signing their certificate. At this point, the client makes sure that the server certificate is both valid and matches DNS name. Then the client verifies the server has the private key.

In the third phase, the client provides an encrypted master key to the server which is then decrypted and used to generate a master secret. This master secret is used to generate symmetric session keys to encrypt and decrypt data.

#### DNS 101 ####

DNS is a discovery service that translates between IP addresses and domain names. A user will query a server for a domain name, the server will return the translated IP address either internally or via a DNS resolver server. The DNS record contains a zone file that matches the domain name to the IP. If the DNS resolver server does not have the record it will query a root DNS server. There are thirteen root servers in the world.

The DNS client is the client device. The resolver is the software that queries DNS. The zone is a part of the DNS database, and the zone file is a physical database for a zone. The nameserver is where zone files are hosted. Root hints are config points at the root server IP. a root server hosts the DNS root zone. The root zone points at TLD authoritative servers. gTLD is a generic top level domain like `.com` while ccTLD is a country-code top level domain like `.uk`.

Record types:
* `NS` name server records verify authority for domain hosts to host DNS records.
* `A` and `AAAA` records directly point to an IP. `AAAA` is for IPv6.
* `CNAME` records include DNS shortcuts and point to domain names, not IP addresses.
* `MX` records verify email servers and use priority values to determine authoritative mail domain.
* `TXT` records provide additional miscellaneous functionality such as proof of domain ownership for third parties.

#### VLANS, Trunks, and Q in Q ####

#### VLANS ####

A LAN is a shared broadcast domain that braodcasts to stations. This does not scale well with more stations added on. Each port is a separate collision domain which limits outages to one station. Physical LANs would divide departments into individual switches which are not connected and thus need their own broadcast domain. This limits inter-department communication especially if a staff member changes to another department but remains at the same desk.

Frame tagging (802.1Q & 802.1AD) introduces new standards in teh frame format by adding a new 32 bit payload for the VLAN ID (VLID). Tagging frames with a VLAN ID helps create separate virtual LANs in the same L2 physical network. They each have a separate broadcast domain and are isolated from all others. 

An issue could potentially arise if two different customers for a communications provider use the same VLAN ID such as 1337. The standard 802.1AD was introduced to resolve this by adding another 32 bit space in the frame for a customer tag (C-TAG) which is distinct from the service tag (S-TAG). A customer can divided their VLANs with S-TAGs while having their own C-TAG.

Q-in-Q allows ISPs to use VLANs across their network while carrying customer traffic which might also be using multiple VLANs.

`.1Q` switches set ports as either access ports or trunk ports. Access ports communicate with stations using normal ethernet (No VLAN tagging). When frames move through an access port to the switch, a VLAN ID is added. When a tagged frame enters an access port, any VLAN ID is removed. A trunk port is a connection between two 1Q-capable devices, usually two switches. The frame and VLAN ID are forwarded between trunk ports. Consequently, a tagged frame will only be sent to other access ports with the same VID or over a trunk port.

AWS Direct Connect uses VLANs, `.1Q` switches, and trunks.

#### Jumbo Frames and MTU ####

A jumbo frame is any frame beyond the maximum Ethernet V2 frame size of 1,500 bytes. Usually a jumbo frame refers to any frame under 9,000 bytes. All frames have a static frame overhead and then a dynamic frame payload. Jumbo frames have a 9,000 byte payload. Normal frames have a higher ratio of overhead to payload, and more space between frames which wastes time. Jumbo payloads pass more payload per frame overhead and it requires fewer frames which means less space between frames on the physical medium.

Jumbo frames are not supported outside a single VPC, over VPN connections, over an IGW, or over an inter-region VPC Peering Connection. Jumbo frames are supported with same-region VPC peering, Direct Connect, and TGW. (TGW can go up to 8,500 bytes). 
## VPCs - Advanced Functionality

### DHCP

The Dynamic Host Configuration Protocol (DHCP) provides an automatic configuration for network resources. It is a standard for passing configuration information to hosts on a TCP/IP network. The `options` field of a DHCP message contains configuration parameters including the domain name, DNS, and `netbios-node-typ`. It starts with L2 broadcast to get info the DHCP server.

AWS automatically creates a set of DHCP options alongside a VPC, which can be manually configured. Each VPC is provided two domain names, an `AmazonProvidedDNS` and a custom DNS domain.

DHCP Option Sets can be associated with 0 or more VPCs. Each VPC can only have up to 1 DHCP Option Set attached. DHCP Option Sets are immutable, once created. Associating a new option set is immediate but the implementation requires a DHCP Renew which takes time.
### VPC Router

Each VPC has an implicit router which is highly available across all AZs in a region. It is scalable and routes traffic between subnets, from external networks into the VPC, and from the VPC into external networks. The VPC router has an interface in every subnet, the `subnet+1` address (default via DHCP Option Set). It is controlled using route tables.

Every VPC is created with a main route table that is default for every subnet in the VPC. Custom route tables can be created and associated with subnets in the VPC, thus removing the main route table. Subnets can only be associated with one route table at a time.

The main route table should be left blank, changes to routing should be done via the custom route table.

### Stateful vs. Stateless Firewalls

TCP is a Layer 4 protocol that works on top of an IP address. Every connection has two parts: the request and the response. The client picks an ephemeral source port and initiates a connection with a known destination port. The server responds using a source port (e.g. `tcp/443`) and the ephemeral destination port picked by the client.

The source port, source IP, destination port, and destination IP uniquely identify the connection.

A request is outbound from the client perspective and inbound from the server perspective. The response outbound from the server perspective, and inbound from the client perspective.

Stateless firewalls require two rules for each state, One ingress and one egress rule for inbound connections, and then one egress and one ingress rule for outbound connections. Stateful firewalls only require one rule for a request or response. It will match ingress and egree traffic according to the session.

### Network Access Control Lists (NACL)

NACLs are an optional layer of VPC security that acts as a stateless firewall for controlling subnet traffic. They regulate subnet boundary traffic, not intra-subnet traffic. NACLs contain rules grouped into inbound and outbound. Inbound rules match traffic entering the subnet, outbound rules match traffic leaving the subnet. NACLs require one request and one response rule for any traffic within VPC, to a VPC, or from a VPC.

Rules match the destination IP/range, port and protocol and allow or deny based on that match. Rules are processed in order, lowest rule number first. Once a match occurs, processing stops. `*` is an implicit deny if nothing else matches (i.e. highest, last rule number).

Custom NACLs can be created and have no subnet association. They start with one inbound implicit deny and one outbound implicit deny. All traffic is denied unless otherwise specified.
### Security Groups

Security Groups are stateful and detect response traffic automatically. An allowed request entails an allowed response. There is no explicit deny, only allow or implicit deny. Specific bad actors cannot be blocked via security groups. Security groups support IP/CIDR and logical resources including other security groups and itself.

Security groups are fundamentally attached to ENI's, not instances. Logical referencing scales via self references, etc. IP changes are handled automatically. Security groups are much more adaptive and user-friendly than NACLs, but they do not block specific bad actors.

### VPC Flow Logs

VPC Flow Logs monitor traffic flow to and from interfaces within a VPC. It does not capture packet contents, only metadata. Third-party packet sniffer solutions would be needed to access packet contents.

VPC Flow Logs can be attached to all ENIs in a VPC, all ENIs in a subnet, or particular ENIs. Flow logs capture metadata from the capture point down. Flow Logs are not real-time. Log destinations include S3 (and query with Athena) or CloudWatch Logs. 

VPC Flow Log Syntax: `[version][account-id][interface-id][srcaddr][dstaddr][srcport][dstport][protocol][packets][bytes][start][end][action][log-status]`.

Action can be `ACCEPT` or `REJECT`.

Metadata servers are not recorded. This includes DHCP, Amazon DNS, and Amazon Windows license.

### AWS IPv6

Only public IPv4 addresses are routable over the public Internet. Private and public IPv4 and subnets are technically and architecturally distinct in AWS. NAT translates the private IPv4s to public. Services never have public IPv4 addressing in a VPC or EC2, only private addressing configuration. Public addresses are handled by the IGW.

All IPv6 addresses in AWS are publicly routable. NAT is not used with IPv6. Each VPC can be IPv6 enabled with a /56.

IPv4 and IPv6 routing are handled separately. IPv6 can be added while creating a VPC/Subnet or addressing can be migrated to IPv6. Can add VPC or subnet range as well as routes and appropriate gateways. Can configure IPv6 on services.

PrivateLink and Interface Endpoints do not support IPv6.
## VPC Public Networking

### IGW for IPv4 and IPv6

A VPC can have zero or one IGWs attached. A IGW can only be attached to one VPC at a time. IGWs are highly available and scalable by default. They work with both IPv4 and IPv6. IPv4 has static NAT while IPv6 routes IPv6 packets in and out of a VPC.

IGWs are used to attached either the AWS Public Zone or the Public Internet.

Egress-only IGWs can be used with IPv6 addresses to account for security issues with non-translated IPv6 addresses.
### BYoIP

AWS owns IPv4 and IPv6 addresses that are allocated to the users as needed, but they are not portable and cannot be used on-premises. AWS is authorized to own these IPs by Regional Internet Registries.

Users can port RIR-recognized IPv4 and IPv6 addresses into AWS and authorize AWS to BGP advertize from ASN 16509 and 14618. The Internet will then see these addresses within AWS.

To import an IP to AWS, the IP owner must create an RSA (AES256) private key and a X509 certificate signed by that key. The public key must be registered with the Resource Public Key Infrastructure of the local RIR. Requests are signed with the private key.

The owner creates and signs a Route Origin Authorization (ROA) to provide with AWS Public Space Network BGP ASN 16509 and 14618. A Route Origin Authorisation is a cryptographically signed object that states which Autonomous System is authorised to originate a certain prefix.

The owner needs to update the RDAP record for the address space with the appropriate RIR by adding the self-signed certificate. This verifies IP ownership. The owner creates an authorization message for AWS and signs with the private key. AWS uses the RDAP to verify IP ownership through the certificate stored in the RIR's RDAP system (with a command like `aws ec2 advertise-byoip-cidr --cidr address-range`). Once this is done AWS can run IP advertisements.

The most specific IPv4 address that can be imported is `/24`, for IPv6 it is `/48` for public CIDRs and `/56` for non-public CIDRs. IPs can only be imported one region at a time. Only five IPv4 and IPv6 address ranges can be used per region per account. IP address ranges cannot be shared with other accounts using AWS Resource Access Manager.

### Bastion Hosts

Bastion hosts sit in the public subnet to provide access to private resources ussing SSH or RDP. It is a server which runs at a network edge and is hardened to withstand attack from public networks. It is a gatekeeper between public and private zones.

A bastion is a subset of jumpbox in that it is hardened to attack. It is essentially an ingress control point with logging, authentication, and security.

Bastion hosts can be replaced by AWS SSM, but they are vendor neutral and still a popular option.

### NAT Instance

A NAT Instance is technically just an EC2 instance running NAT software. It runs NAT AMI Amazon Linux 2018.03 which is at end-of-life. It is not recommended to run NAT Instances.

They are non-specialized and their speed is based on the size and type of EC2 instance. It is necessary to disable source and destination checks to ensure packet delivery. Otherwise NAT will drop the packet. A NAT Instance can also act as a bastion host. It is self-managed and requires greater administrative overhead.

NAT Instance resilience and availability must be self-managed through scripts or other solutions for EC2 autoscaling and Route Table changes based on failures. It does allow the user to combine NAT, Bastion, and port forwards into a single instance. It can be attached to SG and NACL configurations and have VPC Flow Logs for monitoring. It also works across Direct Connect, VPN, and Peering Connections but this is not ideal for high-traffic NAT instances.

### NAT Gateway

A NAT Gateway is an AWS-managed NAT solution which allows private subnet resources to communicate with the Internet or other AWS services while keeping those private resources secure from external connections. A NAT Gateway has an allocated IPv4 public address that routes through the VPC Router to the IGW. The NAT Gateway private IP is mapped onto the public IP.

A route table for private instances points to the NAT Gateway which can then route requests to the IGW. NAT Gateways are AZ resilient but not region resilient. Full region resilience requires deploying a NATGW in each AZ with a route table for each AZ with each NATGW as its target. They have separate failure domains in an AZ. They are AWS-managed, scale up to 45 GB/s, and billing is based on duration and data volume. Full region resilience can become costly.

Other miscellaneous details. NAT Gateways are 5 GB/s by default and scale up to 45 GB/s. Split resources into multiple subnets and use multiple NATGWs for higher resilience and availability. An Elastic IP cannot be changed on a NATGW. A NAT Gateway can handle ~900 connections per second to a single destination. If this is exceeded, CloudWatch Logs will throw the error `ErrorPortAllocation` as no more ports are available for allocation. To avoid NAT Gateway usage costs, use Gateway Endpoints to access S3 or DynamoDB with zero data transfer costs. There are no security groups on a NAT Gateway.

## VPC Endpoints

### AWS PrivateLink

AWS PrivateLink provides private connectivity between VPCs, AWS services, and on-premises applications. The VPC Service provider provides cross-zone load balancing through an endpoint service (multiple to ensure high availability). Permissions are then granted to VPC Consumers and their interface endpoints secured via Security Groups and NACLs. PrivateLink supports IPv4 and TCP but not IPv6. Private DNS is supported with verified domains.

### Gateway VPC Endpoint

Gateway VPC Endpoints allow access to S3 and DynamoDB without public addressing. They add prefix lists to a route table allowing the VPC router to direct traffic flow to the public services. Gateway endpoints are highly available within a region.

The endpoint policy is used to control what it can access. It is regional and therefore can't access cross-region services. Gateway endpoints help prevent leaky buckets by setting privileged access only via gateway endpoints.

### Interface VPC Endpoint

Interface endpoints provide private access to AWS Public services but not to DynamoDB (S3 has recently gained support). It is an ENI added to specific subnets and therefore not highly available by default. For high availability, add one endpoint to one subnet per availability zone in the VPC. Network access is controlled via security groups and endpoint policies can restrict what can be done with the endpoint. They are TCP and IPv4 only as they use PrivateLink.

An endpoint provides a new service endpoint DNS. There is endpoint regional DNS, zonal DNS, or PrivateDNS which overrides the default DNS for services. It essentially injects a service DNS into the VPC so that the IGW can be bypassed. They do not use routing.

## VPC Networking with EC2s

### EC2 Network Architecture

EC2 instances have a primary ENI which cannot be removed from an instance. Additional ENIs can be added or removed from other subnets (multi-homed) but not in other AZs. Multi-ENI can isolate security zones or traffic types between public and private. Security Groups attached to ENIs offer different protection rules. Each ENI is allocated a primary private IPv4 address from the subnet range and can also have secondary IP addresses. Elastic IPs can be mapped onto individual application entrypoints (things that cannot use DNS). There can be one elastic IP per private address. Elastic IPs are charged if they are not associated to an active instance. ENIs also have 1 or more IPv6 addresses, 1 MAC address, and one or more security groups. They are publicly routable. ENIs also include source and destination checks.

### Enhanced Networking: SR-IOV

Networking is traditionally virtualized on EC2. VMs share a physical network interface card (NIC) and the hypervisor mediates access between them. However hypervisor mediation is typically slow. One way around this is a device passthrough which provides direct access from a VM to a network interface card, however tying networking to physical hardware is not ideal for resiliency. SR-IOV connects many VMs to an NIC and offers faster speeds, higher PPS, and lower CPU at higher loads. It is supported on almost all EC2 instances and is required for higher performance. 

With virtualized networks, the OS expects privileged access to the hardware, the hypervisor provides the OS with the appearance that it has privileged access to hardware such as NICs. The hypervisor intercepts and consequently slows it down because it intercepts the calls and requires CPU usage. This model allows hardware to be shared between many VMs but adds overhead and limits performance.

Device (PCI) passthrough is an alternative which allows the VM to passthrough the hypervisor and communicate directly with the hardware using IOMMU. Performance is near bare metal speeds with this approach, but there is a 1:1 mapping between a VM and physical device. It negatively impacts HA as the VM is dependent on the physical hardware. It is hard to scale with this architecture.

Enhanced networking (SR-IOV) makes the NICs virtualization aware. SR-IOV devices offer physical functions and virutal functions. VMs access the VF directly resulting in near bare metal performance. 1 physical device can offer up to 256 VF. VFs are light-weight "sub" devices offered by the physical card. They can be used independently with no hypervisor involvement.

Max speed achieved between two instances is the lowest common denominator (the instance with the lowest speed). For example, Intel 82599 Virtual Function interface supports network speeds of up to 10 GB/s while Elastic Network Adapter (ENA) supports network speeds of up to 100 GB/s. Performance limitations can be introduced if the instances are in separate regions (aggregate bandwidth of 5 GB/s). Single-flow traffic between instance A and instance B is determined by the 5-Tuple limit of source IP, destination IP, source port, destination port, and protocol which results in a maximum of 5 GB/s. Multi-path TCP (MTCP) is an alternative which offers full bandwidth and is more powerful than single-flow traffic.
### Elastic Fabric Adaptor (EFA)

The Elastic Fabric Adapter is a type of EC2 network interface that attached an EC2 instance for HPC or ML applications. One can be attached per instance at launch or shutdown and supports OS bypass to improve performance. Any application that uses MPI or NCCL can use an EFA.

Traditional IP communications add overhead via the kernel and IP stack. Ideally, applications in separate devices are as close as possible. LIBFABRIC runs between user and kernel space and uses the EFA driver to bypass the OS.

There are limitations:
* OS bypass is single subnet only
* Cross subnet/AZ works for normal IP traffic
* OS bypass traffic cannot be routed
* Security groups need an ALLOW ALL, self-referential rule inbound and outbound.

### Cluster Placement Groups

Cluster packs instances close together in **one AZ** for low-latency network performance for tightly-coupled node-to-node communication typical of HPC applications. Cluster has the same rack, sometimes the same host. **10 GB/s per stream** versus the standard 5 GB/s. Lowest latency and max PPS possible in AWS. Little to no resilience. Cluster can span VPC peers but this impacts performance. It requires a supported instance type. Best practice to use the same type of instance at the same time.

### Spread Placement Groups

Spread is used for maximum resilience and availability. Each instance has a distinct rack in multiple AZs. Hard limit of **7 instances per AZ** with isolated infrastructure limit. Each network has its own network and power source. Not supported for dedicated instances or hosts.

### Partition Placement Groups

Need separate partitions for more than 7 instances in an AZ. Divided into a max of 7 partitions per AZ. Each partition group can have as many instances as needed. Partition is used for large parallel running processes. While spread reduces admin overhead, partition allows larger scale.

Instances can be placed in a specific partition or be auto placed. Great for topology aware applications such as HDFS, HBase, and Cassandra. Helps contain impact of failure in an application.


## Networking Automation

CloudFormation, skipped.

## Elastic Load Balancing

### ELB Architecture

A single load balancer contains multiple nodes running in two or more AZs and scale with load. Each ELB is configured with an DNS A record name that resolves to the ELB nodes.

ELBs can be Internet-facing or internal. Internet-facing nodes have public IPs while internal LBs only have private IPs. Load Balancer nodes are configured with listeners which accept traffic on a port and protocol and communicate with targets on a port and protocol. Internet-facing LB nodes can access both public and private EC2 instances. Load Balancers need 8+ free IPs per subnet and a `/27` or larger subnet to allow for scale (`/28` is risky but can also work). The listener configuration controls what the LB does.

Classic Load Balancers do not scale, every unique HTTPS name requires an individual CLB because SNI is not supported. Application Load Balancers automatically scale with 1 SSL per rule. `v2` load balancers support rules and target groups. Host based rules use SNI and an ALB supports consolidation.

The ALB is a Layer 7 LB and listens on HTTP and/or HTTPS. It does not support other Layer 7 protocols such as SMTP or SSH, and definitely does not support TCP/UDP/TLS listeners. It can understand L7 content including cookies, custom headers, user location and app behavior. HTTP(S) is always terminated on the ALB, there is no unbroken SSL connection from the customer to the instance. It is always terminated on the LB. ALBs must have SSL certificates if HTTPS is used. They are also slower than NLBs because they use level 7 traffic. Health checks evaluate application health at layer 7. ALBs have rules which direct connections which arrive at a listener. They are processed in priority order with the last rule being a default catch-all rule. Rule conditions include `host-header`, `http-header`, `http-request-method`, `path-pattern`, `query-string`, and `source-ip`. Rule also contain actions such as forwarding, redirection, fixed response, authentication with oidc, or authentication via Cognito.

The NLB is a layer 4 LB and listens for TCP, TLS, UDP, TCP_UDP traffic. No visibility or understanding of HTTP or HTTPS. No headers, no cookies, and no session stickiness. They are really fast and can handle millions of requests per second. They have 25% of ALB latency. They are ideal for SMTP, SSH, game servers, and financial apps. Health checks however can only check ICMP/TCP handshakes, they do not have application awareness. NLBs can have static IPs which are useful for whitelisting. They can forward TCP to instances with unbroken encryption, unlike ALBs. NLBs can be used with PrivateLink as well.

NLBs are best for unbroken encryption, static IP for whitelisting, fastest performance, non-L7 protocols, and for PrivateLink use. Otherwise, ALB is usually a better solution.

### Other Load Balancing Topics

Connection draining controls what happens when instance are unhealthy or deregistered. Normally all connections are closed and no new conneciton are accepted. Connection draining allows in-flight requests to complete. They are defined on Classic Load Balancers only. They have a timeout between one and 3,600 seconds with a default of 300. `InService` means instance deregistration is in progress. Auto scaling waits for all connections to complete or timeout.

De-registration delay is supported on ALB, NLB and Gateway LBs. They are defined on the target group, not the LB itself. It stops sending requests to deregistering targets while existing connections can continue until they either complete naturally or the deregistration delay is reached. This deregistration delay is also between one and 3,600 seconds with a default of 300 seconds.

`X-Forwarded-For` and `PROXY` protocols are alternative versions of visibility of original client IP address when using proxy servers or load balancers. Direct connections can record customer IPs without issues, however LBs complicate this, so these protocols can be used to assist with IP tracking. `X-Forwarded` is a set of HTTP headers that lists out the sequence of proxies and LBs used with the client IP leftmost on the list. The backend web server needs to be aware of this header. It is supported by CLB and ALB but not NLBs. The `PROXY` protocol works at layer 4 with an additional TCP header. It works with a range of protocols (including HTTP and HTTPS). It works with CLB and NLB. End-to-end encryption is supported by unbroken HTTPS via a TCP listener in combination with a `PROXY` protocol.

LB security policies are a set of ciphers and protocols configured on the listener. It determines what is permissible for the LB to use. The protocol ensures secure client to server communication while the cipher is an algorithm of ciphertext. Client and server present the proper ciphers and protocols, and the best supported one is picked. The user controls the policy between the client and the LB. AWS chosen one is used between the LB and target groups `ELBSecurityPolicy-2016-08`. Newer policies are more secure, but less compatible. If you need forward secrecy use `ELBSecurityPolicy-FS`.

Gateway Load Balancers (GWLB) enable deployment, scaling, and management of virtual 3rd party appliances particularly for security for multi-tenant architectures. It allows for transparent inspection of inbound and outbound traffic. GWLBs include traffic endpoints and balancing technology across multiple backend appliances. Traffic and metadata is tunnelled using the GENEVE protocol. Packets passed through the GWLB are completely unaltered and retain the same source IP and port through the GENEVE encapsulation (tunnel). This works across horizontally scaling appliances. GWLBs can sit in front of ALBs or NLBs and perform inspection there.

## Route 53 Networking

### Route 53 Zones

A R53 Hosted Zone is a DNS DB for a domain. It is globally resilient, created with domain registration via R53 or separately. Hosted Zones reference records that are authoritative for a domain. 

A public hosted zone includes DNS Database (zone file) hosted by R53 Public Name Servers. It is accessible from the public Internet and VPCs. It is hosted on four R53 name servers specific for the zone. The NS records point to those name servers to connect to global DNS. Resource records are created within the hosted zone. Externally registered domains can point at R53 Public Zone.

A R53 private hsoted zone is associated with VPCs and only available in those VPCs. It is possible to use different accounts via the AWS CLI or API. Split-view can also be used with overlapping public and private to split public and internal use (e.g. with Amazon Workspace) with the same zone name. A private zone cannot be queried outside of associated VPCs.

### CNAME vs. ALIAS

An `A` record maps a name to an IP address. A `CNAME` maps a name to another name. A `CNAME` is invalid for the naked/apex domain. This is a problem for ELBs and services which do not have an IP address but use a DNS record. To point to a name from an apex domain, an Alias record can be used. Alias records can also be used for normal records beneath the apex domain. In Route 53, there is no charge for alias requests pointing to AWS resources. Default to picking Alias when possible. It should be the same type as what the record is pointing at. Alias records work for API Gateway, CloudFront, Elastic Beanstalk, ELB, Global Accelerator, and S3.

### Route 53 Routing

Simple routing supports one record per name. Simple routing is used to point toward one service, but it does not support health checks.

Failover routing routes traffic to a backup resource if the primary resource is unhealthy, such as when an EC2 instance has an out of band failure. The health check is set to the primary record. If the primary record is unhealthy, traffic is re-routed to the backup resource. This is common for configuring active/passive failover.

Multi-value routing supports multiple records with the same name. Up to eight healthy records are returned. If more exist, then eight are randomly selected. Client chooses and uses one value. Each record is independent and can have an associated health check. Any records which fail health checks will not be returned when queried. Multivalue improves availability but is not a replacement for load balancing.

Weighted routing associates multiple resources with a single domain and chooses routing based on traffic load. It is used for simple load balancing or testing new software versions (canary deployment). There is a total weight of 100 and measures how often the record is returned. If it is never returned, then the weight is 0. If a chosen record is unhealthy, the process of selection is repeated until a healthy record is chosen.

Latency-based routing routes requests based on the lowest latency. It is used for optimizing performance and user experience. Latency based routing supports one record with the same name in each AWS region. AWS maintains a database of latency between the users' general location and the regions tagged in records. The record returned is the one which offers the lowest estimated latency and is healthy.

Geolocation routing is similar to latency routing but it is based purely on the geographic location of the user using country, continent, US state, or default. An IP check verifies the location of the user and uses this to route the record accordingly. Geolocation does not return the closest record only the relevant location record. It returns the most specific geographic record it can. It can be used for regional restrictions, language-specific content, or load balancing across regional endpoints.

Geoproximity routing serves traffic based on the geographic location of users, measuring how far the DNS query origin is from the record. Records can be tagged with an AWS region or latitude or longitude coordinates. Bias can be added with `+` or `-` to increase a region's size or decrease neighboring regions. This circumvents distance-based routing to specific particular zones that can serve more traffic.

### Route 53 Health Checks

Health checks are separate from Route 53 records but they are used by them. Health checkers are located globally. Health checkers check every 30 seconds (can be set to 10 seconds for a higher price). It can check with TCP, HTTP/HTTPS/ and HTTP/HTTPS with String Matching. If 18% or more of health checkers report as healthy, the health check is reported as healthy. An endpoint can either be healthy or unhealthy. Checks can be endpoint checks, CloudWatch Alarm checks, or checks of checks (calculated).


### Route 53 Interoperability

Route 53 interoperability entails both domain registration and domain hosting. Route 53 can do both or either of these. Route 53 accepts the domain registration fee andthen allocates 4 nameservers for domain hosting. It creates a zone file on the above NS as a domain host. Route 53 communicates with the registry of the TLD as a domain registrar.

What is not common is to have Route 53 as a DNS registrar and another service for domain hosting. Instead more often Route 53 only hosts while another party holds the domain registration. The name servers in the domain registrar must point to Route 53 to authenticate the public hosted zone.

### Advanced Hybrid DNS Architecture Examples

VPC DNS is implemented via the VPC .2 Address (10.16.0.2). .2 is reserved in every subnet. This is the Route 53 resolver for public and associated private hosted zones. Private hosted zones are only accessible from within a VPC which makes hybrid network integration problematic. AWS instances use the Route 53 resolvers. 

Historically this has no ability to forward queries to on-premises resolvers, and so on-premises clients and resolvers had no connectivity to the Route 53 resolver in AWS. There is a DNS boundary between the two environments because the DNS infrastructure cannot communicate.

Before Route 53 endpoints were introduced, a DNS forwarder can be implemented in the AWS VPC through DHCP option sets to forward queries to the on-premises resolver. In this way, AWS resources can maintain their networking and be integrated with on-premises DNS infrastructure.

Route 53 endpoints are made of ENIs accessible over VPN or Direct Connect. They support inbound and outbound traffic so that on-premises DNS queries can be forwarded to the Route 53 resolver. Outbound traffic includes conditional forwarders, Route 53 to on-premises. Rules control what requests are forwarded. Route 53 endpoints are HA and scalable and can handle up to 10,000 queries per second.


## CDN in AWS

### CloudFront Architecture

CloudFront is AWS' CDN solution using caching and the AWS global network. Content is served from an origin, either an S3 origin or a custom origin. A distribution is the configuration unit of CloudFront. Edge locations hold the local cache of data. Regional edge caches are a larger version of an edge location. It provides another layer of caching. Distributions can have different behaviors based on path patterns.

TTL by default is set to 24 hours but other minimum and maximum TTL values can be set. More frequent cache hits equal a lower origin load. Origin headers include `Cache-Control max-age` and `Cache-Control s-maxage` which both set a TTL in seconds. The `Expires` header sets a specific date or time for the cache expiration. Cache invalidation is performed on a distribution and applies to all edge locations, but not immediately as the cache invalidation requires time to propagate. Versioned file names are helpful for managing content caching and preventing the need for cache invalidation.

When first generated, CloudFront generates a default domain name for a `CNAME` record. SSL is supported by default using the `*.cloudfront.net` certificate. Alternate domain names `CNAME` can be used. Verify ownership using a matching certificate. Generate or importing into ACM in `us-east-1`. There are two SSL connection when using CloudFront, viewer to CloudFront and origin to Cloudfront. Both need valid public certificates, self-signed do not qualify.

Historically, every SSL site needed its own IP. Encryption starts at the TCP connection level. Host headers are added later at layer 7 traffic. To reduce the need to generate SSL certificates for every IP. TLS evolved to have SNI as an extension which allows the host to be included in the certificate. This results in many SSL certificates and hosts using a shared IP. Old browsers do not support SNI, so CloudFront charges extra for a dedicated IP ($600 per IP per month per distribution).

Origins need to have certificates issued by a trusted authority (CA). ALB can use ACM, but others (EC2) need to use an external generated certificate that is not self-signed. S3 Origins handle certificates natively.

To secure CloudFront delivery, OAI and cusotm origins can be used. An OAI is a type of identity that can be associated with CloudFront distributions. CloudFront becomes that OAI that can be used in S3 bucket policies. The policy denies all but one or more OAI's. To secure custom origins, custom headers or IP-based FW blocks can be used.

CloudFront Geo Restriction can white or blacklist viewers based on country code. Third party services can be used for more precise geolocation restrictions.


### AWS Certificate Manager

HTTP is simple and insecure, containing many invulnerabilities. HTTPS adds an SSL/TLS layer of encryption added to HTTP. Data is encrypted in-transit. Certificates prove identity via a chain of trust signed by a trusted authority. ACM lets the user run a public or private certificate authority (CA). Applications need to trust the private CA, browsers trust public CAs.

ACM can generate or import certificates. If generated, it can automatically renew. If imported, the customer is responsible for certificate renewal. Certificates can be deployed out to supported services. Note that EC2 is not supported by ACM. Certificates cannot leave the region they are generated or imported into. Certificates cannot be applied across regions. CloudFront operates within `us-east-1` and so CloudFront certificates are always in `us-east-1`.



## Networking Security, Risk, and Compliance

### S3 Access Points

S3 Access Points simplify access management to S3 buckets and objects. Rather than being limited to one bucket with one bucket policy, many access points can be created with different policies, different network access controls, and each access point has its own endpoint address. It can be created with `aws s3control create-access-point`.

### ip-ranges.json

`ip-ranges.json` is a [JSON file](https://ip-ranges.amazonaws.com/ip-ranges.json) that provides a published structure of all public service IP range usage for all AWS regions. The file can be passed into scripts and the AWS CLI to automate security group rules. A SNS Topic and Lambda function can also automate service configuration based on the file.

### AWS Shield and Web Application Firewall

AWS Shield provides AWS resources with DDoS protection. Shield comes in Standard and Advanced versions. Shield Standard includes free usage for Route53 and CloudFront. It provides protection against Layer 3 and Layer 4 DDoS attacks. Shield Advanced offers $3,000 p/m. EC2, ELB, CloudFront, Global Accelerator and Route 53 are only available with Shield Advanced. Shield Advanced also includes a DDoS Response Team and financial insurance.

WAF is a Layer 7 firewall that protects against SQL injections or cross-site scripting and includes geo blocks and rate awareness. It provides a Web Access Control List (WEBACL) integrated with ALB, API Gateway, and CloudFront. Rules are added to a WEBACL and evaluated when traffic arrives.

WAF Rules include WEBACL with rule groups. WEBACL Capacity Units (WCU) account for the complexity of rules. AWS accounts are charged per rules, requests, and WEBACLs per month. WEBACL have a default action: allow or block. Rule actions can allow, block, or count. Rules can be regular or rate-based. Regular rules based on the actions within a rule while rate-based rules are based on activity.

Shield and WAF are often used together to optimize security.


### URL Filtering in a VPC

To approve or deny traffic to particular URLs in a VPC, a self-managed proxy server (layer 7) is needed. NAT Instances and NAT Gateway are not layer 7 and cannot do this. ALBs cannot do this either as they are anti-pattern. Security Groups are layer 5 and do not have URL awareness. NACLs are layer 4 and do not have URL awareness.

A proxy server in a subnet will accept traffic on a proxy server port (usually port 3128) and conditionally forward traffic to the Internet if the URL is not filtered out.
## VPC Peering

VPC peering is a direct encrypted network link between two VPCs. It works in the same or cross-region and same or cross-account. It is possible to have public hostnames resovle to private IPs. Same region security groups can reference peer security groups. VPC Peering does not support transitive peering between many VPCs. It only connects one VPC to one other VPC. VPC Peering connections cannot be created where there is overlap in the VPC CIDRs. It is best practice to never use the same address ranges in multiple VPCs.

Security groups are tied to a VPC in a region. They are attached to ENIs and can reference each other. In the same region, security groups can reference each other. In the same account they can use just security group ID, in different accounts they should reference `account ID/SG ID`. This cannot be done across AWS regions. NACLs are required instead across regions. 

DNS resolves in a public IPv4 DNS to a private IPv4 address. Outside a VPC it resolves to a public or elastic IPv4 address. It can peer across a VPC. There is requester and accepter DNS resolution that can be configured in VPC Peering DNS Options. Both VPCs must be enabled for DNS hostnames and DNS resolution for VPC Peering DNS to work.

There are few ways to work with overlapping CIDR ranges with VPC peering. Routing can be split by placing a separate route table in separate subnets in the original VPC and having each route table route to each conflicting VPC Peers. This means that the VPC Peer is only available from the subnet with its associated route table.

## VPC Hybrid Networking (Virtual)

### IPSEC VPN Fundamentals

IPSEC is a group of protocols that set up a secure tunnels across insecure networks between two peers (local and remote). It provides authentication and encryption. Any data within the VPC tunnels is encrypted and secure.

IPSEC has two phases: (1) establish a secure channel and (2) negotiate the IPsec SA for authenticating traffic. IKE Phase 1 is slow and heavy. Authenticated and asymmetric encryption is established and IKE SA is created (phase 1 tunnel). IKE Phase 2 (fast and agile) uses the keys agreed in phase one. They agree on encryption method and use keys for bulk data transfer.

IKE Phase 1 starts with a certificate or pre-shared key authentication. Each side creates a DH (Diffie Hellman) private key and derives a public key which are then exchanged over the public Internet. Each side takes their private key and the remote peer's public key independelty generates the same shared DH key. They use this key to exchange key materials and agreements over the Internet. Each side generates a symmetrical key using DH key and exchanged material.

In IKE Phase 2, the symmetricla key is used to encrypt and decrypt agreements and pass more key material. Best shared encryption and integrity methods are communicated and agreed on. The DH key and exchanged key material is used to create a symmetrical IPSEC key. The IPSEC key is used for bulk encryption and decryption of interesting traffic. This creates two one-way tunnels.

VPNs can be policy-based or route-based. Policy-based VPNs have rule sets which match traffic and can have different rules or security settings. Route-based VPNs have target matching with prefixes. Route-based feature a single SA pair and single IPSEC key. Policy-based VPNs have a SA pair and unique IPSEC key for each kind of tunnel.


### Virtual Private Gateway

A virtual private gateway (VGW) is a VPN concentrator on the Amazon side of the Site-to-Site VPN connections. It is a gateway object between AWS VPC and non-AWS networks. It can be attached to one VPC max at a time and can be detached and reattached as needed. It maintains its connections even when re-attached to a different VPC. VGWs can be integrated with DX for terminating a Private VIF (if it is in the same region), a DX Gateway, and Site-2-Site VPN (public IPs). It has a private ASN that defaults to 64512. It is highly available by default with multiple AZs. Any VPC route tables with enabled route propagation will have any VGW learned routes added automatically.

A VPN CloudHub architecture would consist of VGW advertizing to other CGWs using the same VGW. Dynamic site-2-site VPNs are created between multiple customer sites and a shared Virtual Private Gateway. Unique BGP ASNs are available for each site. Each business site advertizes a unique CIDR range to the VGW.

### AWS Site-to-Site VPN

A logical connection between a VPC and on-premises network are encrypted using IPSec, running over the public Internet. It is fully highly available if designed and implemented correctly. Site-to-site VPNs are quick to provision and should take less than an hour. It includes a VGW, a customer gateway (CGW), and a VPN connection between the VGW and CGW.

A static VPN uses static routes for the remote siede and added to route tables as static routes. Networks for remote side statically configured on the VPN connection. No load balancing or multi connection failover for a static VPN. 

A dynamic VPN uses the border gateway protocol and is configured on both the customer and AWS side using (ASN). Networks are exchanged via BGP. Routes for the remote side are added to the route tables as tatic routes and then propagated from the route table automatically. This allows for multiple VPN connections and provide HA and traffic distribution.

A VPN has a speed cap of 1.25 GB/s on the AWS but this can be lower depending on customer-side limitations. Latency considerations are inconsistent because they run over the public Internet. Billing is based on hourly cost, GB out cost, and data-cap (on-premises). The main advantage is that they are quick to setup. They can be used with Direct Connect or as a backup to it.

### Border Gateway Protocol (BGP)

BGP is basd on an autonomous system (AS). Routers are controlled by one entity, a network in BGP. ASN are unique and allocated by IANA (0-65535). ASN between 64512 and 65534 are private. BGP operates over `tcp/179`. It is reliable. It is not automatic as peering is manually configured. BGP is a path-vector protocol. It exchanges the best path to a destination between peers. This is the ASPATH. `iBGP` is internal BGP which routes within an AS. `eBGP` is external BGP for routing  between different AS's. BGP exchanges the shortest ASPATH between peers, even if a longer fibre would provide better performance. This can be circumvented through AS Path Prepending which artificially makes the satellite path look longer making the fibre path preferred.

### AWS Global Accelerator

Global Accelerator is an alternative for CloudFront to improve performance. Global Accelerator starts with two anycast IP addresses. Anycast IPs allow a single IP to be in multiple locations. Routing moves traffic to the closest location. Traffic initially uses the public Internet and enters a global accelerator edge location. From the edge, data transits globally across the AWS global backbone network. This means less hops and significantly better performance. Unlike CloudFront, Global Accelerator can carry non-HTTP/S traffic such as TCP or UDP traffic. It also does not cache any content.

### Accelerated VPN

This an enhanced version of the Site-to-Site VPN product. Historically, Site-to-Site VPN uses VGW and CGWs with resilient public space endpoints. It creates two IPSEC tunnels for transit over the public Internet. This means variable performance, latency, and consistency. Alternatively, the VPN can be run over a DX Public VIF for better performance but can be costly.

Logically 2 IPSEC tunnels between the VGW and CGW but physically the transit path is indirect. A Transit Gateway allows a pair of VPN tunnels to provide access to many VPCs but this still uses the public Internet. With Global Accelerator, VPN tunnel IPs are global, and connections are routed to the closest global accelerator edge location. This means low latency, less jitter, and higher throughput. Acceleration can be enabled when creating a TGW VPN attachment. Not compatible with VPNs using a VGW.

### AWS Transit Gateway (TGW)

TGWs are a network transit hub which can simplify networking between VPCs, VPN, and Direct Connect. It is a single network object which is both highly available and scalable. It includes attachments to other networks. Supported attachments include VPCs, Site-to-Site VPNs, and Direct Connect Gateway.

Historically, 4 VPCs could be connected to a customrr site with a single CGW but this means there is only one site of failure. A second CGW could be added, but this would require networking all tunnels to the second CGW as well.

A TGW can sit at the center of a networking hub for VPCs and connect to separate CGWs without setting up duplicate tunnels for each VPC-CGW connection. VPC attachments are configured with a subnet in each AZ where service is required. Peering attachments can be made intra-region or cross-region and within or across accounts using AWS RAM.

At a deeper level, a TGW can connect multiple VPCs and CGWs and attach to a DX Gateway for a Transit VIF. A TGW by default has one route table. The TGWRT uses route propagation learned from the VPC and the BGP. All attachments to the TGW will use the TGWRT by default. TGWs can be peered across regions to other TGWs.

When peering TGWs, no route propagation occurs across peering attachments. They use static routes. Use unique ASNs to account for potential future route propagation features. Public DNS to Private IP resolution is not supported over peers. Peering is encrypted. There can be up to 50 peering attachments per TGW across different regions and accounts. Static routes are required. Attachments can only be associated with one route table, but route tables can be associated with many attachments. Attachments can propagate to many route tables even if they are not directly associated with them.

### Client VPN

Client VPN is a managed implementation of Open VPN that allows client devices to connect securely into AWS VPCs. Any client with OpenVPN software is supported. It connects to a client VPN endpoint associated with one VPC and one or more target networks. Billing is based on network associations. Connection logs are stored in CloudWatch Logs. 

Client routes only occur over the VPN. An alternative is split-tunnel Client VPN. It is not the default, but split tunnel means the ClientVPN routes are added to existing ones. This allows for efficient access to local networks, or the public Internet--avoiding the VPN tunnel.


## VPC Hybrid Networking (Physical)

## Hybrid Services

## Network Billing and Cost Management in Depth

## AWS Disaster Recovery